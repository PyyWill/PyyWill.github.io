---
title:          "Elevating Vision-and-Language Navigation with Viewpoint-Level Episodic Simulation and Memory"
date:           2025
selected:       true
# pub:            "arXiv Preprint"
# pub_pre:        "Submitted to "
pub_post:       'Under Review.'
pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Power Pitch</span>'
pub_date:       "2025"

abstract: >-
   Vision-and-Language Navigation (VLN) in persistent environments provides opportunities for agents to learn from experiences, yet effectively exploiting and organizing episodic memories remains challenging. We introduce Memoir, an agent that uniquely leverages world model simulation to retrieve episodic memories written to specific viewpoints. The world model serves dual purposes: it models agent intent through imagination to guide memory retrieval, while also providing memory representations for past experiences. Our work also introduces a comprehensive memory architecture combining observation memory for visual cues and navigation memory for navigation patterns. Memoir proves its feasibility with two types of advanced VLN settings: iterative and collaborative navigation. Experiments on the IR2R benchmark demonstrate that Memoir achieves a 7% improvement in success rate over the baseline method. Evaluations in multi-agent scenarios also validate its effectiveness in real-time experience sharing across agents.
cover:          /assets/images/covers/cover_Memoir.png
authors:
  - Yunzhe Xu
  - '**Yiyuan Pan**'
  - Zhe Liu
  - Hesheng Wang
---
